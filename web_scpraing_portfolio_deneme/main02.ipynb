{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5528f92-f973-4a97-bee5-895e01f101de",
   "metadata": {},
   "source": [
    "# \"Web Scraping with Selenium to Find a Job\" \n",
    "\n",
    "We will go through 3 main tasks to implement our project:\n",
    "\n",
    "Task 1: Importing libraries.\n",
    "\n",
    "Task 2: Define functions.\n",
    "\n",
    "Task 3: Web scraping with selenium."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc42ec9-e367-454d-a1e7-290cfd658ce9",
   "metadata": {},
   "source": [
    "# Task 1 : Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7746b00f-5b5a-4866-831d-12b56c715dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfbfb6e-6233-4abe-9305-9b421869d22d",
   "metadata": {},
   "source": [
    "# Task 2 : Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f68a27f-889d-4c30-830e-1e1c54a38a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sleep function \n",
    "def sleep(x):\n",
    "    time.sleep(x)\n",
    "\n",
    "# Wait for a certain measure of time before throwing an exception\n",
    "def wait(x):\n",
    "    driver.implicitly_wait(x)\n",
    "\n",
    "# Click Function\n",
    "def click_bann_byID(ID):\n",
    "    actions = ActionChains(driver)\n",
    "    akzeptieren = driver.find_element(By.ID, ID)\n",
    "    actions.click(akzeptieren).perform()\n",
    "    wait(10)\n",
    "    sleep(0.5)\n",
    "\n",
    "\n",
    "# Find Element Function\n",
    "def find_element(H):\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    list_header = [title.text for title in header]\n",
    "    return list_header\n",
    "\n",
    "\n",
    "# Find Elements Function\n",
    "def find_elements_HPCO(H,P,C,O):\n",
    "    header = driver.find_elements(By.CLASS_NAME, H)\n",
    "    publish = driver.find_elements(By.CLASS_NAME, P)\n",
    "    company = driver.find_elements(By.CLASS_NAME, C)\n",
    "    ort = driver.find_elements(By.CLASS_NAME, O) \n",
    "\n",
    "    list_header = [title.text for title in header]\n",
    "    list_publish = [pub.text for pub in publish]\n",
    "    list_company = [comp.text for comp in company]\n",
    "    list_ort = [o.text for o in ort]\n",
    "    return list_header, list_publish, list_company, list_ort\n",
    "\n",
    "# Scroll Down Function\n",
    "def scroll_down(x):\n",
    "    n=0\n",
    "    while n < x:\n",
    "        n+=1\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        sleep(1.5)\n",
    "        actions.key_down(Keys.PAGE_UP).perform()\n",
    "        sleep(0.10)\n",
    "        actions.key_down(Keys.PAGE_DOWN).perform()\n",
    "        wait(10)\n",
    "        sleep(2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3feb03-1eeb-40e8-aa2a-48d4fea21a1a",
   "metadata": {},
   "source": [
    "# Web Scraping with Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f24bb0e-db35-4c09-950f-541b8871c539",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 01 - STEPSTONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962f38df-d454-44d7-afcc-8b1e7917ae67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- StepStone Job Searching Selenium Project ----------------------\n",
      "Create Driver\n",
      "Go to Website\n",
      "Banned\n",
      "h pc o\n",
      "Header 25 Publish 25 Company 24 Ort 25 Desc 25 Link 25\n",
      "Page Number : 2, DataFrame Shape : (25, 6)\n",
      "Page Number : 3, DataFrame Shape : (25, 6)\n",
      "Page Number : 4, DataFrame Shape : (25, 6)\n",
      "Page Number : 5, DataFrame Shape : (25, 6)\n",
      "Page Number : 6, DataFrame Shape : (25, 6)\n",
      "DataFrame End : (150, 6)\n",
      "Code Runned No Problem\n",
      "Time = 0:01:04.508044\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Title : Web Scrapping by Selenium \n",
    "Project Purpose: From StepStone scrap data for some Job Titels\n",
    "1 - Create Driver\n",
    "2 - Go to Website\n",
    "3 - Create ActionChain Object\n",
    "    3.1 - Click Banned \n",
    "4 - Take Title and Infos from Page\n",
    "    4.1 - Create Lists \n",
    "    4.2 - Create DataFrame\n",
    "    4.3 - Repeat Process\n",
    "    4.4 - Print and Save DataFrame\n",
    "'''\n",
    "\n",
    "print('---------------------- StepStone Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# Link Descriptions\n",
    "link_original_stepstone = 'https://www.stepstone.de/jobs/data-analyst/in-rietberg?radius=50&page=2'\n",
    "\n",
    "website_name = 'stepstone'\n",
    "job_name = 'Data Engineer'\n",
    "#job_name = 'Data Analyst'\n",
    "#job_name = 'Data Scientist'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 100\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "print('Create Driver')\n",
    "\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}&sort=2&action=sort_publish'\n",
    "\n",
    "driver.get(link)\n",
    "wait(5)\n",
    "sleep(2)\n",
    "print('Go to Website')\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'ccmgt_explicit_accept'\n",
    "click_bann_byID(ID)\n",
    "print('Banned')\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Publish_Time ,Company, City\n",
    "H, P, C, O = ('res-29pyh9', 'res-rf8k2x', 'res-hbyqhf', 'res-1wf9en7')\n",
    "list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O)\n",
    "print('h pc o')\n",
    "# 4.2 - Description and Page number of results\n",
    "description = driver.find_elements(By.CLASS_NAME, 'res-17md5or')\n",
    "#result = driver.find_elements(By.CLASS_NAME, 'resultlist-1jx3vjx')\n",
    "\n",
    "\n",
    "# 4.3 - Get Links 'res-1dwe62q'\n",
    "list_link01  = driver.find_elements(By.CLASS_NAME, 'res-1dwe62q')\n",
    "list_link = [link.get_attribute('href') for link in list_link01]\n",
    "\n",
    "# 4.4 - Get Texts for each finding\n",
    "list_description = [des.text for des in description]\n",
    "print('Header',len(list_header), 'Publish',len(list_publish), 'Company',len(list_company[1:]), 'Ort',len(list_ort), 'Desc', len(list_description), 'Link',len(list_link))\n",
    "\n",
    "# 4.5 - Total Search Page Number\n",
    "#list_result = [res.text for res in result]\n",
    "#number_of_page = int(list_result[-2])\n",
    "#print(f'Number of Jobs Pages = {number_of_page}')\n",
    "\n",
    "# 4.6 - DataFrame df\n",
    "d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "\n",
    "number_of_page = 6\n",
    "# 4.7 Repeat Process for every Web Page\n",
    "while  page_number < number_of_page:\n",
    "    page_number+=1\n",
    "    \n",
    "    # 4.7.1 - Go to another page\n",
    "    link = f'https://www.stepstone.de/jobs/{job_link}/in-{ort_link}?radius={radius}&page={page_number}'\n",
    "    driver.get(link)\n",
    "    wait(5)\n",
    "    sleep(1.5)\n",
    "    \n",
    "    # 4.7.2 - Find the elements and get the Texts\n",
    "    list_header, list_publish, list_company, list_ort = find_elements_HPCO(H,P,C,O) \n",
    "    description = driver.find_elements(By.CLASS_NAME, 'res-17md5or')\n",
    "    list_description = [des.text for des in description]\n",
    "    list_link01  = driver.find_elements(By.CLASS_NAME, 'res-1dwe62q')\n",
    "    list_link = [link.get_attribute('href') for link in list_link01]\n",
    " \n",
    "    # 4.7.3 - Create new page Dataframe\n",
    "    d = dict(job_title=np.array(list_header), publish=np.array(list_publish), company=np.array(list_company[1:]), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "    df2 = pd.DataFrame.from_dict(d, orient='index')\n",
    "    df2 = df2.T\n",
    "    \n",
    "    # 4.7.4 - Concatenate the DataFrames\n",
    "    df = pd.concat([df,df2], axis=0, ignore_index=True)\n",
    "    print(f'Page Number : {page_number}, DataFrame Shape : {df2.shape}')\n",
    "\n",
    "\n",
    "# 5.1 - Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "df['website'] = website_name\n",
    "time_ = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['date'] = time_\n",
    "job_name2 = job_name.replace(' ', '_')\n",
    "df['search_title'] = job_name2\n",
    "\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "job_name3 = job_name.replace(' ', '-')\n",
    "time_ = datetime.today().strftime('%Y-%m-%d')\n",
    "df.to_csv(f'{path}/{job_name3}-{website_name}-{time_}.csv', index=False)\n",
    "\n",
    "# 6 - Quit\n",
    "end =datetime.now() \n",
    "print('Code Runned No Problem')\n",
    "print(f'Time = {end - start}')\n",
    "sleep(5)\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f6803-bbb4-481c-aec4-701e30a9e105",
   "metadata": {},
   "source": [
    "# Links with searching status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9dd81a-2d93-4d02-a614-1d4dedd2582c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "https://www.stepstone.de/jobs/data-engineer/in-rietberg?radius=100\n",
    "\n",
    "https://www.stepstone.de/jobs/data-engineer/in-rietberg?radius=100&page=1&sort=2&action=sort_publish\n",
    "\n",
    "https://www.stepstone.de/jobs/data-engineer/in-rietberg?radius=100&page=2&sort=2&action=sort_publish\n",
    "\n",
    "https://www.stepstone.de/jobs/data-engineer/in-rietberg?radius=100&page=2&sort=1&action=facet_selected%3bage%3bage_7&ag=age_7 # son 1 hafta\n",
    "\n",
    "https://www.stepstone.de/jobs/data-engineer/in-rietberg?radius=100&page=1&sort=1&action=facet_selected%3bage%3bage_1&ag=age_1 # son 24 saat\n",
    "\n",
    "\n",
    "https://www.xing.com/jobs/search?keywords=Data%20Engineer&location=Rietberg&radius=100&sort=relevance \n",
    "\n",
    "https://www.xing.com/jobs/search?keywords=Data%20Engineer&location=Rietberg&radius=100&sort=date # newest first\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c8c74d-e06b-4d6e-9bbb-5550555aa081",
   "metadata": {},
   "source": [
    "# Xing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "577f5fdf-7c16-48ef-ab7c-60f5c8dd80c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- Xing Job Searching Selenium Project ----------------------\n",
      "DataFrame End : (20, 9)\n",
      "[40, 20, 20, 20, 20]\n",
      "Finish 2023-03-10 09:04:55\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>publish</th>\n",
       "      <th>company</th>\n",
       "      <th>city</th>\n",
       "      <th>description</th>\n",
       "      <th>link</th>\n",
       "      <th>website</th>\n",
       "      <th>date</th>\n",
       "      <th>search_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Software Engineer (m/w/d)</td>\n",
       "      <td>Vor 7 Stunden</td>\n",
       "      <td>inserve GmbH</td>\n",
       "      <td>Osnabrück</td>\n",
       "      <td>Engineering und Data Streaming Dein Spielfeld?</td>\n",
       "      <td>https://www.xing.com/jobs/osnabrueck-senior-so...</td>\n",
       "      <td>xing</td>\n",
       "      <td>2023-03-10 09:04:55</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead Engineer, Powertrain Verification</td>\n",
       "      <td>Vor 8 Stunden</td>\n",
       "      <td>Vestas Wind Systems A/S</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Responsibilities As Lead Engineer - Powertrain...</td>\n",
       "      <td>https://www.xing.com/jobs/dortmund-lead-engine...</td>\n",
       "      <td>xing</td>\n",
       "      <td>2023-03-10 09:04:55</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineer Sports (all genders)</td>\n",
       "      <td>Vor 15 Stunden</td>\n",
       "      <td>adesso SE</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Pipelines, Data Ingest und Date Processing.</td>\n",
       "      <td>https://www.xing.com/jobs/dortmund-data-engine...</td>\n",
       "      <td>xing</td>\n",
       "      <td>2023-03-10 09:04:55</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Architect (all genders)</td>\n",
       "      <td>Vor 15 Stunden</td>\n",
       "      <td>adesso SE</td>\n",
       "      <td>Dortmund</td>\n",
       "      <td>Das Competence Center Data Engineering ist ver...</td>\n",
       "      <td>https://www.xing.com/jobs/dortmund-data-archit...</td>\n",
       "      <td>xing</td>\n",
       "      <td>2023-03-10 09:04:55</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Engineer (all genders)</td>\n",
       "      <td>Vor 15 Stunden</td>\n",
       "      <td>adesso SE</td>\n",
       "      <td>Münster</td>\n",
       "      <td>Als Data Engineer bist du Teil eines innovativ...</td>\n",
       "      <td>https://www.xing.com/jobs/muenster-data-engine...</td>\n",
       "      <td>xing</td>\n",
       "      <td>2023-03-10 09:04:55</td>\n",
       "      <td>Data Engineer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                job_title         publish  \\\n",
       "0        Senior Software Engineer (m/w/d)   Vor 7 Stunden   \n",
       "1  Lead Engineer, Powertrain Verification   Vor 8 Stunden   \n",
       "2      Data Engineer Sports (all genders)  Vor 15 Stunden   \n",
       "3            Data Architect (all genders)  Vor 15 Stunden   \n",
       "4             Data Engineer (all genders)  Vor 15 Stunden   \n",
       "\n",
       "                   company       city  \\\n",
       "0             inserve GmbH  Osnabrück   \n",
       "1  Vestas Wind Systems A/S   Dortmund   \n",
       "2                adesso SE   Dortmund   \n",
       "3                adesso SE   Dortmund   \n",
       "4                adesso SE    Münster   \n",
       "\n",
       "                                         description  \\\n",
       "0     Engineering und Data Streaming Dein Spielfeld?   \n",
       "1  Responsibilities As Lead Engineer - Powertrain...   \n",
       "2        Pipelines, Data Ingest und Date Processing.   \n",
       "3  Das Competence Center Data Engineering ist ver...   \n",
       "4  Als Data Engineer bist du Teil eines innovativ...   \n",
       "\n",
       "                                                link website  \\\n",
       "0  https://www.xing.com/jobs/osnabrueck-senior-so...    xing   \n",
       "1  https://www.xing.com/jobs/dortmund-lead-engine...    xing   \n",
       "2  https://www.xing.com/jobs/dortmund-data-engine...    xing   \n",
       "3  https://www.xing.com/jobs/dortmund-data-archit...    xing   \n",
       "4  https://www.xing.com/jobs/muenster-data-engine...    xing   \n",
       "\n",
       "                  date   search_title  \n",
       "0  2023-03-10 09:04:55  Data Engineer  \n",
       "1  2023-03-10 09:04:55  Data Engineer  \n",
       "2  2023-03-10 09:04:55  Data Engineer  \n",
       "3  2023-03-10 09:04:55  Data Engineer  \n",
       "4  2023-03-10 09:04:55  Data Engineer  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('---------------------- Xing Job Searching Selenium Project ----------------------')\n",
    "start=datetime.now()  \n",
    "# Link Descriptions\n",
    "link_original_xing = 'https://www.xing.com/jobs/search?keywords=Data%20Engineer&location=Rietberg&page=1&radius=100'\n",
    "\n",
    "website_name = 'xing'\n",
    "job_name = 'Data Engineer'\n",
    "#job_name = 'Data Analyst'\n",
    "#job_name = 'Data Scientist'\n",
    "ort_ = 'Rietberg'\n",
    "radius = 50\n",
    "page_number = 1\n",
    "\n",
    "#  1 - Create Driver\n",
    "Path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/chromedriver'\n",
    "driver = webdriver.Chrome(Path)\n",
    "\n",
    "#  2 - Go to Website\n",
    "job_link = job_name.replace(' ', '-').lower()\n",
    "ort_link = ort_.lower()\n",
    "link = f'https://www.xing.com/jobs/search?keywords=Data%20Engineer&location=Rietberg&page=1&radius=100&sort=date'\n",
    "\n",
    "driver.get(link)\n",
    "wait(10)\n",
    "sleep(2)\n",
    "\n",
    "#  3 - ActionChain Object created\n",
    "# 3.1 - Click Banned Accept\n",
    "ID = 'consent-accept-button'\n",
    "click_bann_byID(ID)\n",
    "\n",
    "# 4 -  Take Infos from Page\n",
    "# 4.1 - Headers, Publish_Time ,Company, City\n",
    "H = 'utils-line-clamp-lineClamp2-dfe26aab'\n",
    "D = 'list-item-job-teaser-list-item-highlight-bb8ddbb6'\n",
    "L = 'list-item-job-teaser-list-item-location-a5b28738'\n",
    "ALL = 'list-item-job-teaser-list-item-listItem-f04c772e'\n",
    "\n",
    "\n",
    "list_header = find_element(H)\n",
    "list_description = find_element(D)\n",
    "list_ort = find_element(L)\n",
    "list_all = find_element(ALL)\n",
    "\n",
    "list_publish = []\n",
    "list_full_time = [] \n",
    "for i in list_all:\n",
    "    date = i.split('\\n')[-2]\n",
    "    time_ = i.split('\\n')[-3]\n",
    "    list_publish.append(date)\n",
    "    list_full_time.append(time_)\n",
    "\n",
    "list_title =[]\n",
    "list_company = []\n",
    "n = 0\n",
    "while n < len(list_header):\n",
    "    list_title.append(list_header[n])\n",
    "    list_company.append(list_header[n+1])\n",
    "    n += 2\n",
    "\n",
    "# 4.3 - Get Links\n",
    "Link = 'list-item-job-teaser-list-item-listItem-f04c772e'\n",
    "header = driver.find_elements(By.CLASS_NAME, Link)\n",
    "list_link = [link.get_attribute('href') for link in header]\n",
    "\n",
    "# 4.4 - DataFrame df\n",
    "d = dict(job_title=np.array(list_title), publish=np.array(list_publish), company=np.array(list_company), city=np.array(list_ort) , description=np.array(list_description), link=np.array(list_link))\n",
    "df = pd.DataFrame.from_dict(d, orient='index')\n",
    "df = df.T\n",
    "df['website'] = website_name\n",
    "time_now = datetime.today().strftime('%Y-%m-%d %H:%M:%S')\n",
    "df['date'] = time_now\n",
    "df['search_title'] = job_name\n",
    "\n",
    "\n",
    "# 5.1 - Save Data as csv \n",
    "print(f'DataFrame End : {df.shape}')\n",
    "path = '/Users/macbook/Desktop/projects/Github_Repositories/Portfolio Projects/02 - Web_Scraping_Job_Search/data'\n",
    "df.to_csv(f'{path}/{job_name}.csv', mode='a', index=False, header=False)\n",
    "\n",
    "list_of_list = [list_header, list_description, list_ort, list_publish, list_link]\n",
    "print([len(i) for i in list_of_list])\n",
    "\n",
    "sleep(2)\n",
    "driver.quit()\n",
    "print('Finish', time_now)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863fddf-c358-4541-a7eb-3c506bb5ba3b",
   "metadata": {},
   "source": [
    "# Connect Database POSTGRESQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d147a67-6218-4403-a838-4f3944807bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Brunel',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Campusjäger by Workwise',)\n",
      "('Vesterling AG',)\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "conn = psycopg2.connect(database=\"JOB\",\n",
    "\t\t\t\t\t\tuser='postgres', password=1984,\n",
    "\t\t\t\t\t\thost='127.0.0.1', port='5432'\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "sql = '''CREATE TABLE IF NOT EXISTS dataeng(job_title varchar(300) NOT NULL,\\\n",
    "publish varchar(30),\\\n",
    "company varchar(300),\\\n",
    "city varchar(300),\\\n",
    "description varchar(300),\\\n",
    "link varchar(300),\\\n",
    "website varchar(30),\\\n",
    "date timestamp,\\\n",
    "search_title varchar(20));'''\n",
    "\n",
    "cursor.execute(sql)\n",
    "\n",
    "\n",
    "# connection string: driver://username:password@server/database\n",
    "engine = create_engine('postgresql+psycopg2://postgres:1984@localhost/JOB')\n",
    "\n",
    "#  Note:  if_exists can be append, replace, fail.  \n",
    "df.to_sql('dataeng', engine, if_exists='append', index = False)\n",
    "\n",
    "\n",
    "sql2 = '''select company from dataeng Where publish LIKE '%hours%' '''\n",
    "cursor.execute(sql2)\n",
    "for i in cursor.fetchall():\n",
    "\tprint(i)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6525d1a8-883a-4aea-b32a-54b18fe64e87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/macbook/Desktop/projects/Github_Repositories/Trainings/web_scoraing_portfolio_deneme'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c3cc09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
